{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DDP_BE16B029",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-mu9oAVleH0E",
        "outputId": "c8e73bf3-270c-437e-c4da-e70ead96c146"
      },
      "source": [
        "!wget -nc https://raw.githubusercontent.com/brainhack101/IntroDL/master/notebooks/2019/Eklund/requirements-gpu.txt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-07-20 05:52:27--  https://raw.githubusercontent.com/brainhack101/IntroDL/master/notebooks/2019/Eklund/requirements-gpu.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 90 [text/plain]\n",
            "Saving to: ‘requirements-gpu.txt’\n",
            "\n",
            "requirements-gpu.tx 100%[===================>]      90  --.-KB/s    in 0s      \n",
            "\n",
            "2021-07-20 05:52:28 (3.49 MB/s) - ‘requirements-gpu.txt’ saved [90/90]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ua2-jIlveMMH"
      },
      "source": [
        "!pip install -r requirements-gpu.txt"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L3PGuFRZgYjU"
      },
      "source": [
        "%tensorflow_version 1.x\n",
        "from keras.layers import Layer, Input, Dropout, Conv2D, Activation, add, UpSampling2D, Conv2DTranspose, Flatten\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization, InputSpec\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.engine.topology import Network\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from progress.bar import Bar\n",
        "import datetime\n",
        "import time\n",
        "import json\n",
        "import csv\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S7E4grECgYm8"
      },
      "source": [
        "!pip install -U scipy==1.2.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DKA2VrAygclN"
      },
      "source": [
        "'''from keras.layers import Layer, Input, Conv2D, Activation, add, BatchNormalization, UpSampling2D, ZeroPadding2D, Conv2DTranspose, Flatten, MaxPooling2D, AveragePooling2D\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization, InputSpec\n",
        "'''\n",
        "import os\n",
        "from PIL import Image\n",
        "import glob\n",
        "'''\n",
        "#from keras_contrib.layers.normalization import InstanceNormalization, InputSpec\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.backend import mean\n",
        "from keras.models import Model, model_from_json\n",
        "from keras.utils import plot_model\n",
        "from keras.engine.topology import Network\n",
        "'''\n",
        "from collections import OrderedDict\n",
        "from scipy.misc import imsave, toimage  # has depricated\n",
        "'''import numpy as np\n",
        "import random\n",
        "import datetime\n",
        "import time\n",
        "import json\n",
        "import math\n",
        "import csv\n",
        "import sys\n",
        "import os\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "'''\n",
        "#import load_data\n",
        "\n",
        "%tensorflow_version 1.x\n",
        "from keras.layers import Layer, Input, Dropout, Conv2D, Activation, add, UpSampling2D, \\\n",
        "    Conv2DTranspose, Flatten\n",
        "from keras_contrib.layers.normalization.instancenormalization import InstanceNormalization, InputSpec\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.layers.core import Dense\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Model\n",
        "from keras.engine.topology import Network\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "from progress.bar import Bar\n",
        "import datetime\n",
        "import time\n",
        "import json\n",
        "import csv\n",
        "import sys\n",
        "import os\n",
        "import random\n",
        "\n",
        "import keras.backend as K\n",
        "import tensorflow as tf\n",
        "\n",
        "def load_data(nr_of_channels, batch_size=1, nr_A_train_imgs=None, nr_B_train_imgs=None,\n",
        "              nr_A_test_imgs=None, nr_B_test_imgs=None, subfolder='',\n",
        "              generator=False, D_model=None, use_multiscale_discriminator=False, use_supervised_learning=False, REAL_LABEL=1.0):\n",
        "\n",
        "    trainA_path = os.path.join('data', subfolder, 'trainA')\n",
        "    trainB_path = os.path.join('data', subfolder, 'trainB')\n",
        "    testA_path = os.path.join('data', subfolder, 'testA')\n",
        "    testB_path = os.path.join('data', subfolder, 'testB')\n",
        "\n",
        "    trainA_image_names = os.listdir(trainA_path)\n",
        "    if nr_A_train_imgs != None:\n",
        "        trainA_image_names = trainA_image_names[:nr_A_train_imgs]\n",
        "\n",
        "    trainB_image_names = os.listdir(trainB_path)\n",
        "    if nr_B_train_imgs != None:\n",
        "        trainB_image_names = trainB_image_names[:nr_B_train_imgs]\n",
        "\n",
        "    testA_image_names = os.listdir(testA_path)\n",
        "    if nr_A_test_imgs != None:\n",
        "        testA_image_names = testA_image_names[:nr_A_test_imgs]\n",
        "\n",
        "    testB_image_names = os.listdir(testB_path)\n",
        "    if nr_B_test_imgs != None:\n",
        "        testB_image_names = testB_image_names[:nr_B_test_imgs]\n",
        "\n",
        "    if generator:\n",
        "        return data_sequence(trainA_path, trainB_path, trainA_image_names, trainB_image_names, batch_size=batch_size)  # D_model, use_multiscale_discriminator, use_supervised_learning, REAL_LABEL)\n",
        "    else:\n",
        "        trainA_images = create_image_array(trainA_image_names, trainA_path, nr_of_channels)\n",
        "        trainB_images = create_image_array(trainB_image_names, trainB_path, nr_of_channels)\n",
        "        testA_images = create_image_array(testA_image_names, testA_path, nr_of_channels)\n",
        "        testB_images = create_image_array(testB_image_names, testB_path, nr_of_channels)\n",
        "        return {\"trainA_images\": trainA_images, \"trainB_images\": trainB_images,\n",
        "                \"testA_images\": testA_images, \"testB_images\": testB_images,\n",
        "                \"trainA_image_names\": trainA_image_names,\n",
        "                \"trainB_image_names\": trainB_image_names,\n",
        "                \"testA_image_names\": testA_image_names,\n",
        "                \"testB_image_names\": testB_image_names}\n",
        "\n",
        "\n",
        "def create_image_array(image_list, image_path, nr_of_channels):\n",
        "    image_array = []\n",
        "    for image_name in image_list:\n",
        "        if image_name[-1].lower() == 'g':  # to avoid e.g. thumbs.db files\n",
        "            if nr_of_channels == 1:  # Gray scale image -> MR image\n",
        "                image = np.array(Image.open(os.path.join(image_path, image_name)))\n",
        "                image = image[:, :, np.newaxis]\n",
        "            else:                   # RGB image -> 3 channels\n",
        "                image = np.array(Image.open(os.path.join(image_path, image_name)))\n",
        "            image = normalize_array(image)\n",
        "            image_array.append(image)\n",
        "\n",
        "    return np.array(image_array)\n",
        "  \n",
        "  \n",
        "  # If using 16 bit depth images, use the formula 'array = array / 32767.5 - 1' instead\n",
        "def normalize_array(array):\n",
        "    array = array / 127.5 - 1\n",
        "    return array\n",
        "\n",
        "\n",
        "class data_sequence():\n",
        "\n",
        "    def __init__(self, trainA_path, trainB_path, image_list_A, image_list_B, batch_size=1):  # , D_model, use_multiscale_discriminator, use_supervised_learning, REAL_LABEL):\n",
        "        self.batch_size = batch_size\n",
        "        self.train_A = []\n",
        "        self.train_B = []\n",
        "        for image_name in image_list_A:\n",
        "            if image_name[-1].lower() == 'g':  # to avoid e.g. thumbs.db files\n",
        "                self.train_A.append(os.path.join(trainA_path, image_name))\n",
        "        for image_name in image_list_B:\n",
        "            if image_name[-1].lower() == 'g':  # to avoid e.g. thumbs.db files\n",
        "                self.train_B.append(os.path.join(trainB_path, image_name))\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(max(len(self.train_A), len(self.train_B)) / float(self.batch_size))\n",
        "\n",
        "    def __getitem__(self, idx):  # , use_multiscale_discriminator, use_supervised_learning):if loop_index + batch_size >= min_nr_imgs:\n",
        "        if idx >= min(len(self.train_A), len(self.train_B)):\n",
        "            # If all images soon are used for one domain,\n",
        "            # randomly pick from this domain\n",
        "            if len(self.train_A) <= len(self.train_B):\n",
        "                indexes_A = np.random.randint(len(self.train_A), size=self.batch_size)\n",
        "                batch_A = []\n",
        "                for i in indexes_A:\n",
        "                    batch_A.append(self.train_A[i])\n",
        "                batch_B = self.train_B[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "            else:\n",
        "                indexes_B = np.random.randint(len(self.train_B), size=self.batch_size)\n",
        "                batch_B = []\n",
        "                for i in indexes_B:\n",
        "                    batch_B.append(self.train_B[i])\n",
        "                batch_A = self.train_A[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "        else:\n",
        "            batch_A = self.train_A[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "            batch_B = self.train_B[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
        "\n",
        "        real_images_A = create_image_array(batch_A, '', 3)\n",
        "        real_images_B = create_image_array(batch_B, '', 3)\n",
        "\n",
        "        return real_images_A, real_images_B  # input_data, target_data\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "np.random.seed(seed=12345)\n",
        "\n",
        "\n",
        "class CycleGAN():\n",
        "    def __init__(self, lr_D=2e-4, lr_G=2e-4, image_shape=(240, 240, 1),\n",
        "                 date_time_string_addition='', image_folder='MR'):\n",
        "        self.img_shape = image_shape\n",
        "        self.channels = self.img_shape[-1]\n",
        "        self.normalization = InstanceNormalization\n",
        "        # Hyper parameters\n",
        "        self.lambda_1 = 10.0  # Cyclic loss weight A_2_B\n",
        "        self.lambda_2 = 10.0  # Cyclic loss weight B_2_A\n",
        "        self.lambda_D = 1.0  # Weight for loss from discriminator guess on synthetic images\n",
        "        self.learning_rate_D = lr_D\n",
        "        self.learning_rate_G = lr_G\n",
        "        self.generator_iterations = 1  # Number of generator training iterations in each training loop\n",
        "        self.discriminator_iterations = 1  # Number of generator training iterations in each training loop\n",
        "        self.beta_1 = 0.5\n",
        "        self.beta_2 = 0.999\n",
        "        self.batch_size = 1\n",
        "        self.epochs = 100  # choose multiples of 25 since the models are save each 25th epoch\n",
        "        self.save_interval = 1\n",
        "        self.synthetic_pool_size = 50\n",
        "\n",
        "        # Linear decay of learning rate, for both discriminators and generators\n",
        "        self.use_linear_decay = True\n",
        "        self.decay_epoch = 101  # The epoch where the linear decay of the learning rates start\n",
        "\n",
        "        # Identity loss - sometimes send images from B to G_A2B (and the opposite) to teach identity mappings\n",
        "        self.use_identity_learning = False\n",
        "        self.identity_mapping_modulus = 10  # Identity mapping will be done each time the iteration number is divisable with this number\n",
        "\n",
        "        # PatchGAN - if false the discriminator learning rate should be decreased\n",
        "        self.use_patchgan = True\n",
        "\n",
        "        # Multi scale discriminator - if True the generator have an extra encoding/decoding step to match discriminator information access\n",
        "        self.use_multiscale_discriminator = False\n",
        "\n",
        "        # Resize convolution - instead of transpose convolution in deconvolution layers (uk) - can reduce checkerboard artifacts but the blurring might affect the cycle-consistency\n",
        "        self.use_resize_convolution = False\n",
        "\n",
        "        # Supervised learning part - for MR images - comparison\n",
        "        self.use_supervised_learning = False\n",
        "        self.supervised_weight = 10.0\n",
        "\n",
        "        # Fetch data during training instead of pre caching all images - might be necessary for large datasets\n",
        "        self.use_data_generator = False\n",
        "\n",
        "        # Tweaks\n",
        "        self.REAL_LABEL = 1.0  # Use e.g. 0.9 to avoid training the discriminators to zero loss\n",
        "\n",
        "        # Used as storage folder name\n",
        "        self.date_time = time.strftime('%Y%m%d-%H%M%S', time.localtime()) + date_time_string_addition\n",
        "\n",
        "        # optimizer\n",
        "        self.opt_D = Adam(self.learning_rate_D, self.beta_1, self.beta_2)\n",
        "        self.opt_G = Adam(self.learning_rate_G, self.beta_1, self.beta_2)\n",
        "\n",
        "        # ======= Discriminator model ==========\n",
        "        if self.use_multiscale_discriminator:\n",
        "            D_A = self.modelMultiScaleDiscriminator()\n",
        "            D_B = self.modelMultiScaleDiscriminator()\n",
        "            loss_weights_D = [0.5, 0.5] # 0.5 since we train on real and synthetic images\n",
        "        else:\n",
        "            D_A = self.modelDiscriminator()\n",
        "            D_B = self.modelDiscriminator()\n",
        "            loss_weights_D = [0.5]  # 0.5 since we train on real and synthetic images\n",
        "        # D_A.summary()\n",
        "\n",
        "        # Discriminator builds\n",
        "        image_A = Input(shape=self.img_shape)\n",
        "        image_B = Input(shape=self.img_shape)\n",
        "        guess_A = D_A(image_A)\n",
        "        guess_B = D_B(image_B)\n",
        "        self.D_A = Model(inputs=image_A, outputs=guess_A, name='D_A_model')\n",
        "        self.D_B = Model(inputs=image_B, outputs=guess_B, name='D_B_model')\n",
        "\n",
        "        # self.D_A.summary()\n",
        "        # self.D_B.summary()\n",
        "        self.D_A.compile(optimizer=self.opt_D,\n",
        "                         loss=self.lse,\n",
        "                         loss_weights=loss_weights_D)\n",
        "        self.D_B.compile(optimizer=self.opt_D,\n",
        "                         loss=self.lse,\n",
        "                         loss_weights=loss_weights_D)\n",
        "\n",
        "        # Use Networks to avoid falsy keras error about weight descripancies\n",
        "        self.D_A_static = Network(inputs=image_A, outputs=guess_A, name='D_A_static_model')\n",
        "        self.D_B_static = Network(inputs=image_B, outputs=guess_B, name='D_B_static_model')\n",
        "\n",
        "        # ======= Generator model ==========\n",
        "        # Do note update discriminator weights during generator training\n",
        "        self.D_A_static.trainable = False\n",
        "        self.D_B_static.trainable = False\n",
        "\n",
        "        # Generators\n",
        "        self.G_A2B = self.modelGenerator(name='G_A2B_model')\n",
        "        self.G_B2A = self.modelGenerator(name='G_B2A_model')\n",
        "        # self.G_A2B.summary()\n",
        "\n",
        "        if self.use_identity_learning:\n",
        "            self.G_A2B.compile(optimizer=self.opt_G, loss='MAE')\n",
        "            self.G_B2A.compile(optimizer=self.opt_G, loss='MAE')\n",
        "\n",
        "        # Generator builds\n",
        "        real_A = Input(shape=self.img_shape, name='real_A')\n",
        "        real_B = Input(shape=self.img_shape, name='real_B')\n",
        "        synthetic_B = self.G_A2B(real_A)\n",
        "        synthetic_A = self.G_B2A(real_B)\n",
        "        dA_guess_synthetic = self.D_A_static(synthetic_A)\n",
        "        dB_guess_synthetic = self.D_B_static(synthetic_B)\n",
        "        reconstructed_A = self.G_B2A(synthetic_B)\n",
        "        reconstructed_B = self.G_A2B(synthetic_A)\n",
        "\n",
        "        model_outputs = [reconstructed_A, reconstructed_B]\n",
        "        compile_losses = [self.cycle_loss, self.cycle_loss,\n",
        "                          self.lse, self.lse]\n",
        "        compile_weights = [self.lambda_1, self.lambda_2,\n",
        "                           self.lambda_D, self.lambda_D]\n",
        "\n",
        "        if self.use_multiscale_discriminator:\n",
        "            for _ in range(2):\n",
        "                compile_losses.append(self.lse)\n",
        "                compile_weights.append(self.lambda_D)  # * 1e-3)  # Lower weight to regularize the model\n",
        "            for i in range(2):\n",
        "                model_outputs.append(dA_guess_synthetic[i])\n",
        "                model_outputs.append(dB_guess_synthetic[i])\n",
        "        else:\n",
        "            model_outputs.append(dA_guess_synthetic)\n",
        "            model_outputs.append(dB_guess_synthetic)\n",
        "\n",
        "        if self.use_supervised_learning:\n",
        "            model_outputs.append(synthetic_A)\n",
        "            model_outputs.append(synthetic_B)\n",
        "            compile_losses.append('MAE')\n",
        "            compile_losses.append('MAE')\n",
        "            compile_weights.append(self.supervised_weight)\n",
        "            compile_weights.append(self.supervised_weight)\n",
        "\n",
        "        self.G_model = Model(inputs=[real_A, real_B],\n",
        "                             outputs=model_outputs,\n",
        "                             name='G_model')\n",
        "\n",
        "        self.G_model.compile(optimizer=self.opt_G,\n",
        "                             loss=compile_losses,\n",
        "                             loss_weights=compile_weights)\n",
        "        # self.G_A2B.summary()\n",
        "\n",
        "        # ======= Data ==========\n",
        "        # Use 'None' to fetch all available images\n",
        "        nr_A_train_imgs = None\n",
        "        nr_B_train_imgs = None\n",
        "        nr_A_test_imgs = None\n",
        "        nr_B_test_imgs = None\n",
        "\n",
        "        if self.use_data_generator:\n",
        "            print('--- Using dataloader during training ---')\n",
        "        else:\n",
        "            print('--- Caching data ---')\n",
        "        sys.stdout.flush()\n",
        "\n",
        "        if self.use_data_generator:\n",
        "            self.data_generator = load_data(\n",
        "                nr_of_channels=self.batch_size, generator=True, subfolder=image_folder)\n",
        "\n",
        "            # Only store test images\n",
        "            nr_A_train_imgs = 0\n",
        "            nr_B_train_imgs = 0\n",
        "\n",
        "        data = load_data(nr_of_channels=self.channels,\n",
        "                                   batch_size=self.batch_size,\n",
        "                                   nr_A_train_imgs=nr_A_train_imgs,\n",
        "                                   nr_B_train_imgs=nr_B_train_imgs,\n",
        "                                   nr_A_test_imgs=nr_A_test_imgs,\n",
        "                                   nr_B_test_imgs=nr_B_test_imgs,\n",
        "                                   subfolder=image_folder)\n",
        "\n",
        "        self.A_train = data[\"trainA_images\"]\n",
        "        self.B_train = data[\"trainB_images\"]\n",
        "        self.A_test = data[\"testA_images\"]\n",
        "        self.B_test = data[\"testB_images\"]\n",
        "        self.testA_image_names = data[\"testA_image_names\"]\n",
        "        self.testB_image_names = data[\"testB_image_names\"]\n",
        "        if not self.use_data_generator:\n",
        "            print('Data has been loaded')\n",
        "\n",
        "        # ======= Create designated run folder and store meta data ==========\n",
        "        directory = os.path.join('images', self.date_time)\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "        self.writeMetaDataToJSON()\n",
        "\n",
        "        # ======= Avoid pre-allocating GPU memory ==========\n",
        "        # TensorFlow wizardry\n",
        "        #config = tf.ConfigProto()\n",
        "        config=tf.compat.v1.ConfigProto()\n",
        "\n",
        "        # Don't pre-allocate memory; allocate as-needed\n",
        "        config.gpu_options.allow_growth = True\n",
        "\n",
        "        # Create a session with the above options specified.\n",
        "        K.tensorflow_backend.set_session(tf.Session(config=config))\n",
        "\n",
        "        # ===== Tests ======\n",
        "        # Simple Model\n",
        "#         self.G_A2B = self.modelSimple('simple_T1_2_T2_model')\n",
        "#         self.G_B2A = self.modelSimple('simple_T2_2_T1_model')\n",
        "#         self.G_A2B.compile(optimizer=Adam(), loss='MAE')\n",
        "#         self.G_B2A.compile(optimizer=Adam(), loss='MAE')\n",
        "#         # self.trainSimpleModel()\n",
        "#         self.load_model_and_generate_synthetic_images()\n",
        "\n",
        "        # ======= Initialize training ==========\n",
        "        sys.stdout.flush()\n",
        "        #plot_model(self.G_A2B, to_file='GA2B_expanded_model_new.png', show_shapes=True)\n",
        "        self.train(epochs=self.epochs, batch_size=self.batch_size, save_interval=self.save_interval)\n",
        "        #self.load_model_and_generate_synthetic_images()\n",
        "\n",
        "#===============================================================================\n",
        "# Architecture functions\n",
        "\n",
        "    def ck(self, x, k, use_normalization, stride):\n",
        "        x = Conv2D(filters=k, kernel_size=4, strides=stride, padding='same')(x)\n",
        "        # Normalization is not done on the first discriminator layer\n",
        "        if use_normalization:\n",
        "            x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
        "        x = LeakyReLU(alpha=0.2)(x)\n",
        "        return x\n",
        "\n",
        "    def c7Ak(self, x, k):\n",
        "        x = Conv2D(filters=k, kernel_size=7, strides=1, padding='valid')(x)\n",
        "        x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
        "        x = Activation('relu')(x)\n",
        "        return x\n",
        "\n",
        "    def dk(self, x, k):\n",
        "        x = Conv2D(filters=k, kernel_size=3, strides=2, padding='same')(x)\n",
        "        x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
        "        x = Activation('relu')(x)\n",
        "        return x\n",
        "\n",
        "    def Rk(self, x0):\n",
        "        k = int(x0.shape[-1])\n",
        "        # first layer\n",
        "        x = Conv2D(filters=k, kernel_size=3, strides=1, padding='same')(x0)\n",
        "        x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
        "        x = Activation('relu')(x)\n",
        "        # second layer\n",
        "        x = Conv2D(filters=k, kernel_size=3, strides=1, padding='same')(x)\n",
        "        x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
        "        # merge\n",
        "        x = add([x, x0])\n",
        "        return x\n",
        "\n",
        "    def uk(self, x, k):\n",
        "        # (up sampling followed by 1x1 convolution <=> fractional-strided 1/2)\n",
        "        if self.use_resize_convolution:\n",
        "            x = UpSampling2D(size=(2, 2))(x)  # Nearest neighbor upsampling\n",
        "            x = ReflectionPadding2D((1, 1))(x)\n",
        "            x = Conv2D(filters=k, kernel_size=3, strides=1, padding='valid')(x)\n",
        "        else:\n",
        "            x = Conv2DTranspose(filters=k, kernel_size=3, strides=2, padding='same')(x)  # this matches fractionally stided with stride 1/2\n",
        "        x = self.normalization(axis=3, center=True, epsilon=1e-5)(x, training=True)\n",
        "        x = Activation('relu')(x)\n",
        "        return x\n",
        "\n",
        "#===============================================================================\n",
        "# Models\n",
        "\n",
        "    def modelMultiScaleDiscriminator(self, name=None):\n",
        "        x1 = Input(shape=self.img_shape)\n",
        "        x2 = AveragePooling2D(pool_size=(2, 2))(x1)\n",
        "        #x4 = AveragePooling2D(pool_size=(2, 2))(x2)\n",
        "\n",
        "        out_x1 = self.modelDiscriminator('D1')(x1)\n",
        "        out_x2 = self.modelDiscriminator('D2')(x2)\n",
        "        #out_x4 = self.modelDiscriminator('D4')(x4)\n",
        "\n",
        "        return Model(inputs=x1, outputs=[out_x1, out_x2], name=name)\n",
        "\n",
        "    def modelDiscriminator(self, name=None):\n",
        "        # Specify input\n",
        "        input_img = Input(shape=self.img_shape)\n",
        "        # Layer 1 (#Instance normalization is not used for this layer)\n",
        "        x = self.ck(input_img, 64, False, 2)\n",
        "        # Layer 2\n",
        "        x = self.ck(x, 128, True, 2)\n",
        "        # Layer 3\n",
        "        x = self.ck(x, 256, True, 2)\n",
        "        # Layer 4\n",
        "        x = self.ck(x, 512, True, 1)\n",
        "        # Output layer\n",
        "        if self.use_patchgan:\n",
        "            x = Conv2D(filters=1, kernel_size=4, strides=1, padding='same')(x)\n",
        "        else:\n",
        "            x = Flatten()(x)\n",
        "            x = Dense(1)(x)\n",
        "        #x = Activation('sigmoid')(x) - No sigmoid to avoid near-fp32 machine epsilon discriminator cost\n",
        "        return Model(inputs=input_img, outputs=x, name=name)\n",
        "\n",
        "    def modelGenerator(self, name=None):\n",
        "        # Specify input\n",
        "        input_img = Input(shape=self.img_shape)\n",
        "        # Layer 1\n",
        "        x = ReflectionPadding2D((3, 3))(input_img)\n",
        "        x = self.c7Ak(x, 32)\n",
        "        # Layer 2\n",
        "        x = self.dk(x, 64)\n",
        "        # Layer 3\n",
        "        x = self.dk(x, 128)\n",
        "\n",
        "        if self.use_multiscale_discriminator:\n",
        "            # Layer 3.5\n",
        "            x = self.dk(x, 256)\n",
        "\n",
        "        # Layer 4-12: Residual layer\n",
        "        for _ in range(4, 13):\n",
        "            x = self.Rk(x)\n",
        "\n",
        "        if self.use_multiscale_discriminator:\n",
        "            # Layer 12.5\n",
        "            x = self.uk(x, 128)\n",
        "\n",
        "        # Layer 13\n",
        "        x = self.uk(x, 64)\n",
        "        # Layer 14\n",
        "        x = self.uk(x, 32)\n",
        "        x = ReflectionPadding2D((3, 3))(x)\n",
        "        x = Conv2D(self.channels, kernel_size=7, strides=1)(x)\n",
        "        x = Activation('tanh')(x)  # They say they use Relu but really they do not\n",
        "        return Model(inputs=input_img, outputs=x, name=name)\n",
        "\n",
        "#===============================================================================\n",
        "# Test - simple model\n",
        "    def modelSimple(self, name=None):\n",
        "        inputImg = Input(shape=self.img_shape)\n",
        "        #x = Conv2D(1, kernel_size=5, strides=1, padding='same')(inputImg)\n",
        "        #x = Dense(self.channels)(x)\n",
        "        x = Conv2D(256, kernel_size=1, strides=1, padding='same')(inputImg)\n",
        "        x = Activation('relu')(x)\n",
        "        x = Conv2D(self.channels, kernel_size=1, strides=1, padding='same')(x)\n",
        "\n",
        "        return Model(input=inputImg, output=x, name=name)\n",
        "\n",
        "    def trainSimpleModel(self):\n",
        "        real_A = self.A_test[0]\n",
        "        real_B = self.B_test[0]\n",
        "        real_A = real_A[np.newaxis, :, :, :]\n",
        "        real_B = real_B[np.newaxis, :, :, :]\n",
        "        epochs = 200\n",
        "        for epoch in range(epochs):\n",
        "            print('Epoch {} started'.format(epoch))\n",
        "            self.G_A2B.fit(x=self.A_train, y=self.B_train, epochs=1, batch_size=1)\n",
        "            self.G_B2A.fit(x=self.B_train, y=self.A_train, epochs=1, batch_size=1)\n",
        "            #loss = self.G_A2B.train_on_batch(x=real_A, y=real_B)\n",
        "            #print('loss: ', loss)\n",
        "            synthetic_image_A = self.G_B2A.predict(real_B, batch_size=1)\n",
        "            synthetic_image_B = self.G_A2B.predict(real_A, batch_size=1)\n",
        "            self.save_tmp_images(real_A, real_B, synthetic_image_A, synthetic_image_B)\n",
        "\n",
        "        self.saveModel(self.G_A2B, 200)\n",
        "        self.saveModel(self.G_B2A, 200)\n",
        "\n",
        "#===============================================================================\n",
        "# Training\n",
        "    def train(self, epochs, batch_size=1, save_interval=1):\n",
        "        def run_training_iteration(loop_index, epoch_iterations):\n",
        "            # ======= Discriminator training ==========\n",
        "                # Generate batch of synthetic images\n",
        "            synthetic_images_B = self.G_A2B.predict(real_images_A)\n",
        "            synthetic_images_A = self.G_B2A.predict(real_images_B)\n",
        "            synthetic_images_A = synthetic_pool_A.query(synthetic_images_A)\n",
        "            synthetic_images_B = synthetic_pool_B.query(synthetic_images_B)\n",
        "\n",
        "            for _ in range(self.discriminator_iterations):\n",
        "                DA_loss_real = self.D_A.train_on_batch(x=real_images_A, y=ones)\n",
        "                DB_loss_real = self.D_B.train_on_batch(x=real_images_B, y=ones)\n",
        "                DA_loss_synthetic = self.D_A.train_on_batch(x=synthetic_images_A, y=zeros)\n",
        "                DB_loss_synthetic = self.D_B.train_on_batch(x=synthetic_images_B, y=zeros)\n",
        "                if self.use_multiscale_discriminator:\n",
        "                    DA_loss = sum(DA_loss_real) + sum(DA_loss_synthetic)\n",
        "                    DB_loss = sum(DB_loss_real) + sum(DB_loss_synthetic)\n",
        "                    print('DA_losses: ', np.add(DA_loss_real, DA_loss_synthetic))\n",
        "                    print('DB_losses: ', np.add(DB_loss_real, DB_loss_synthetic))\n",
        "                else:\n",
        "                    DA_loss = DA_loss_real + DA_loss_synthetic\n",
        "                    DB_loss = DB_loss_real + DB_loss_synthetic\n",
        "                D_loss = DA_loss + DB_loss\n",
        "\n",
        "                if self.discriminator_iterations > 1:\n",
        "                    print('D_loss:', D_loss)\n",
        "                    sys.stdout.flush()\n",
        "\n",
        "            # ======= Generator training ==========\n",
        "            target_data = [real_images_A, real_images_B]  # Compare reconstructed images to real images\n",
        "            if self.use_multiscale_discriminator:\n",
        "                for i in range(2):\n",
        "                    target_data.append(ones[i])\n",
        "                    target_data.append(ones[i])\n",
        "            else:\n",
        "                target_data.append(ones)\n",
        "                target_data.append(ones)\n",
        "\n",
        "            if self.use_supervised_learning:\n",
        "                target_data.append(real_images_A)\n",
        "                target_data.append(real_images_B)\n",
        "\n",
        "            for _ in range(self.generator_iterations):\n",
        "                G_loss = self.G_model.train_on_batch(\n",
        "                    x=[real_images_A, real_images_B], y=target_data)\n",
        "                if self.generator_iterations > 1:\n",
        "                    print('G_loss:', G_loss)\n",
        "                    sys.stdout.flush()\n",
        "\n",
        "            gA_d_loss_synthetic = G_loss[1]\n",
        "            gB_d_loss_synthetic = G_loss[2]\n",
        "            reconstruction_loss_A = G_loss[3]\n",
        "            reconstruction_loss_B = G_loss[4]\n",
        "\n",
        "            # Identity training\n",
        "            if self.use_identity_learning and loop_index % self.identity_mapping_modulus == 0:\n",
        "                G_A2B_identity_loss = self.G_A2B.train_on_batch(\n",
        "                    x=real_images_B, y=real_images_B)\n",
        "                G_B2A_identity_loss = self.G_B2A.train_on_batch(\n",
        "                    x=real_images_A, y=real_images_A)\n",
        "                print('G_A2B_identity_loss:', G_A2B_identity_loss)\n",
        "                print('G_B2A_identity_loss:', G_B2A_identity_loss)\n",
        "\n",
        "            # Update learning rates\n",
        "            if self.use_linear_decay and epoch > self.decay_epoch:\n",
        "                self.update_lr(self.D_A, decay_D)\n",
        "                self.update_lr(self.D_B, decay_D)\n",
        "                self.update_lr(self.G_model, decay_G)\n",
        "\n",
        "            # Store training data\n",
        "            DA_losses.append(DA_loss)\n",
        "            DB_losses.append(DB_loss)\n",
        "            gA_d_losses_synthetic.append(gA_d_loss_synthetic)\n",
        "            gB_d_losses_synthetic.append(gB_d_loss_synthetic)\n",
        "            gA_losses_reconstructed.append(reconstruction_loss_A)\n",
        "            gB_losses_reconstructed.append(reconstruction_loss_B)\n",
        "\n",
        "            GA_loss = gA_d_loss_synthetic + reconstruction_loss_A\n",
        "            GB_loss = gB_d_loss_synthetic + reconstruction_loss_B\n",
        "            D_losses.append(D_loss)\n",
        "            GA_losses.append(GA_loss)\n",
        "            GB_losses.append(GB_loss)\n",
        "            G_losses.append(G_loss)\n",
        "            reconstruction_loss = reconstruction_loss_A + reconstruction_loss_B\n",
        "            reconstruction_losses.append(reconstruction_loss)\n",
        "\n",
        "            print('\\n')\n",
        "            print('Epoch----------------', epoch, '/', epochs)\n",
        "            print('Loop index----------------', loop_index + 1, '/', epoch_iterations)\n",
        "            print('D_loss: ', D_loss)\n",
        "            print('G_loss: ', G_loss[0])\n",
        "            print('reconstruction_loss: ', reconstruction_loss)\n",
        "            print('dA_loss:', DA_loss)\n",
        "            print('DB_loss:', DB_loss)\n",
        "\n",
        "            if loop_index % 20 == 0:\n",
        "                # Save temporary images continously\n",
        "                self.save_tmp_images(real_images_A, real_images_B, synthetic_images_A, synthetic_images_B)\n",
        "                self.print_ETA(start_time, epoch, epoch_iterations, loop_index)\n",
        "\n",
        "        # ======================================================================\n",
        "        # Begin training\n",
        "        # ======================================================================\n",
        "        training_history = OrderedDict()\n",
        "\n",
        "        DA_losses = []\n",
        "        DB_losses = []\n",
        "        gA_d_losses_synthetic = []\n",
        "        gB_d_losses_synthetic = []\n",
        "        gA_losses_reconstructed = []\n",
        "        gB_losses_reconstructed = []\n",
        "\n",
        "        GA_losses = []\n",
        "        GB_losses = []\n",
        "        reconstruction_losses = []\n",
        "        D_losses = []\n",
        "        G_losses = []\n",
        "\n",
        "        # Image pools used to update the discriminators\n",
        "        synthetic_pool_A = ImagePool(self.synthetic_pool_size)\n",
        "        synthetic_pool_B = ImagePool(self.synthetic_pool_size)\n",
        "\n",
        "        # self.saveImages('(init)')\n",
        "\n",
        "        # labels\n",
        "        if self.use_multiscale_discriminator:\n",
        "            label_shape1 = (batch_size,) + self.D_A.output_shape[0][1:]\n",
        "            label_shape2 = (batch_size,) + self.D_A.output_shape[1][1:]\n",
        "            #label_shape4 = (batch_size,) + self.D_A.output_shape[2][1:]\n",
        "            ones1 = np.ones(shape=label_shape1) * self.REAL_LABEL\n",
        "            ones2 = np.ones(shape=label_shape2) * self.REAL_LABEL\n",
        "            #ones4 = np.ones(shape=label_shape4) * self.REAL_LABEL\n",
        "            ones = [ones1, ones2]  # , ones4]\n",
        "            zeros1 = ones1 * 0\n",
        "            zeros2 = ones2 * 0\n",
        "            #zeros4 = ones4 * 0\n",
        "            zeros = [zeros1, zeros2]  # , zeros4]\n",
        "        else:\n",
        "            label_shape = (batch_size,) + self.D_A.output_shape[1:]\n",
        "            ones = np.ones(shape=label_shape) * self.REAL_LABEL\n",
        "            zeros = ones * 0\n",
        "\n",
        "        # Linear decay\n",
        "        if self.use_linear_decay:\n",
        "            decay_D, decay_G = self.get_lr_linear_decay_rate()\n",
        "\n",
        "        # Start stopwatch for ETAs\n",
        "        start_time = time.time()\n",
        "\n",
        "        for epoch in range(1, epochs + 1):\n",
        "            if self.use_data_generator:\n",
        "                loop_index = 1\n",
        "                for images in self.data_generator:\n",
        "                    real_images_A = images[0]\n",
        "                    real_images_B = images[1]\n",
        "                    if len(real_images_A.shape) == 3:\n",
        "                        real_images_A = real_images_A[:, :, :, np.newaxis]\n",
        "                        real_images_B = real_images_B[:, :, :, np.newaxis]\n",
        "\n",
        "                    # Run all training steps\n",
        "                    run_training_iteration(loop_index, self.data_generator.__len__())\n",
        "\n",
        "                    # Store models\n",
        "                    if loop_index % 20000 == 0:\n",
        "                        self.saveModel(self.D_A, loop_index)\n",
        "                        self.saveModel(self.D_B, loop_index)\n",
        "                        self.saveModel(self.G_A2B, loop_index)\n",
        "                        self.saveModel(self.G_B2A, loop_index)\n",
        "\n",
        "                    # Break if loop has ended\n",
        "                    if loop_index >= self.data_generator.__len__():\n",
        "                        break\n",
        "\n",
        "                    loop_index += 1\n",
        "\n",
        "            else:  # Train with all data in cache\n",
        "                A_train = self.A_train\n",
        "                B_train = self.B_train\n",
        "                random_order_A = np.random.randint(len(A_train), size=len(A_train))\n",
        "                random_order_B = np.random.randint(len(B_train), size=len(B_train))\n",
        "                epoch_iterations = max(len(random_order_A), len(random_order_B))\n",
        "                min_nr_imgs = min(len(random_order_A), len(random_order_B))\n",
        "\n",
        "                # If we want supervised learning the same images form\n",
        "                # the two domains are needed during each training iteration\n",
        "                if self.use_supervised_learning:\n",
        "                    random_order_B = random_order_A\n",
        "                for loop_index in range(0, epoch_iterations, batch_size):\n",
        "                    if loop_index + batch_size >= min_nr_imgs:\n",
        "                        # If all images soon are used for one domain,\n",
        "                        # randomly pick from this domain\n",
        "                        if len(A_train) <= len(B_train):\n",
        "                            indexes_A = np.random.randint(len(A_train), size=batch_size)\n",
        "\n",
        "                            # if all images are used for the other domain\n",
        "                            if loop_index + batch_size >= epoch_iterations:  \n",
        "                                indexes_B = random_order_B[epoch_iterations-batch_size: \n",
        "                                                           epoch_iterations]\n",
        "                            else: # if not used, continue iterating...\n",
        "                                indexes_B = random_order_B[loop_index:\n",
        "                                                           loop_index + batch_size]\n",
        "\n",
        "                        else: # if len(B_train) <= len(A_train)\n",
        "                            indexes_B = np.random.randint(len(B_train), size=batch_size)\n",
        "                            \n",
        "                             # if all images are used for the other domain\n",
        "                            if loop_index + batch_size >= epoch_iterations:  \n",
        "                                indexes_A = random_order_A[epoch_iterations-batch_size: \n",
        "                                                           epoch_iterations]\n",
        "                            else: # if not used, continue iterating...\n",
        "                                indexes_A = random_order_A[loop_index:\n",
        "                                                           loop_index + batch_size]\n",
        "\n",
        "                    else:\n",
        "                        indexes_A = random_order_A[loop_index:\n",
        "                                                   loop_index + batch_size]\n",
        "                        indexes_B = random_order_B[loop_index:\n",
        "                                                   loop_index + batch_size]\n",
        "\n",
        "                    sys.stdout.flush()\n",
        "                    real_images_A = A_train[indexes_A]\n",
        "                    real_images_B = B_train[indexes_B]\n",
        "\n",
        "                    # Run all training steps\n",
        "                    run_training_iteration(loop_index, epoch_iterations)\n",
        "\n",
        "            #================== within epoch loop end ==========================\n",
        "\n",
        "            if epoch % save_interval == 0:\n",
        "                print('\\n', '\\n', '-------------------------Saving images for epoch', epoch, '-------------------------', '\\n', '\\n')\n",
        "                self.saveImages(epoch, real_images_A, real_images_B)\n",
        "\n",
        "            if epoch % 20 == 0:\n",
        "                # self.saveModel(self.G_model)\n",
        "                self.saveModel(self.D_A, epoch)\n",
        "                self.saveModel(self.D_B, epoch)\n",
        "                self.saveModel(self.G_A2B, epoch)\n",
        "                self.saveModel(self.G_B2A, epoch)\n",
        "\n",
        "            training_history = {\n",
        "                'DA_losses': DA_losses,\n",
        "                'DB_losses': DB_losses,\n",
        "                'gA_d_losses_synthetic': gA_d_losses_synthetic,\n",
        "                'gB_d_losses_synthetic': gB_d_losses_synthetic,\n",
        "                'gA_losses_reconstructed': gA_losses_reconstructed,\n",
        "                'gB_losses_reconstructed': gB_losses_reconstructed,\n",
        "                'D_losses': D_losses,\n",
        "                'G_losses': G_losses,\n",
        "                'reconstruction_losses': reconstruction_losses}\n",
        "            self.writeLossDataToFile(training_history)\n",
        "\n",
        "            # Flush out prints each loop iteration\n",
        "            sys.stdout.flush()\n",
        "\n",
        "#===============================================================================\n",
        "# Help functions\n",
        "\n",
        "    def lse(self, y_true, y_pred):\n",
        "        loss = tf.reduce_mean(tf.squared_difference(y_pred, y_true))\n",
        "        return loss\n",
        "\n",
        "    def cycle_loss(self, y_true, y_pred):\n",
        "        loss = tf.reduce_mean(tf.abs(y_pred - y_true))\n",
        "        return loss\n",
        "\n",
        "    def truncateAndSave(self, real_, real, synthetic, reconstructed, path_name):\n",
        "        if len(real.shape) > 3:\n",
        "            real = real[0]\n",
        "            synthetic = synthetic[0]\n",
        "            reconstructed = reconstructed[0]\n",
        "\n",
        "        # Append and save\n",
        "        if real_ is not None:\n",
        "            if len(real_.shape) > 4:\n",
        "                real_ = real_[0]\n",
        "            image = np.hstack((real_[0], real, synthetic, reconstructed))\n",
        "        else:\n",
        "            image = np.hstack((real, synthetic, reconstructed))\n",
        "\n",
        "        if self.channels == 1:\n",
        "            image = image[:, :, 0]\n",
        "\n",
        "        toimage(image, cmin=-1, cmax=1).save(path_name)\n",
        "\n",
        "    def saveImages(self, epoch, real_image_A, real_image_B, num_saved_images=1):\n",
        "        directory = os.path.join('images', self.date_time)\n",
        "        if not os.path.exists(os.path.join(directory, 'A')):\n",
        "            os.makedirs(os.path.join(directory, 'A'))\n",
        "            os.makedirs(os.path.join(directory, 'B'))\n",
        "            os.makedirs(os.path.join(directory, 'Atest'))\n",
        "            os.makedirs(os.path.join(directory, 'Btest'))\n",
        "\n",
        "        testString = ''\n",
        "\n",
        "        real_image_Ab = None\n",
        "        real_image_Ba = None\n",
        "        for i in range(num_saved_images + 1):\n",
        "            if i == num_saved_images:\n",
        "                real_image_A = self.A_test[0]\n",
        "                real_image_B = self.B_test[0]\n",
        "                real_image_A = np.expand_dims(real_image_A, axis=0)\n",
        "                real_image_B = np.expand_dims(real_image_B, axis=0)\n",
        "                testString = 'test'\n",
        "                if self.channels == 1:  # Use the paired data for MR images\n",
        "                    real_image_Ab = self.B_test[0]\n",
        "                    real_image_Ba = self.A_test[0]\n",
        "                    real_image_Ab = np.expand_dims(real_image_Ab, axis=0)\n",
        "                    real_image_Ba = np.expand_dims(real_image_Ba, axis=0)\n",
        "            else:\n",
        "                #real_image_A = self.A_train[rand_A_idx[i]]\n",
        "                #real_image_B = self.B_train[rand_B_idx[i]]\n",
        "                if len(real_image_A.shape) < 4:\n",
        "                    real_image_A = np.expand_dims(real_image_A, axis=0)\n",
        "                    real_image_B = np.expand_dims(real_image_B, axis=0)\n",
        "                if self.channels == 1:  # Use the paired data for MR images\n",
        "                    real_image_Ab = real_image_B  # self.B_train[rand_A_idx[i]]\n",
        "                    real_image_Ba = real_image_A  # self.A_train[rand_B_idx[i]]\n",
        "                    real_image_Ab = np.expand_dims(real_image_Ab, axis=0)\n",
        "                    real_image_Ba = np.expand_dims(real_image_Ba, axis=0)\n",
        "\n",
        "            synthetic_image_B = self.G_A2B.predict(real_image_A)\n",
        "            synthetic_image_A = self.G_B2A.predict(real_image_B)\n",
        "            reconstructed_image_A = self.G_B2A.predict(synthetic_image_B)\n",
        "            reconstructed_image_B = self.G_A2B.predict(synthetic_image_A)\n",
        "\n",
        "            self.truncateAndSave(real_image_Ab, real_image_A, synthetic_image_B, reconstructed_image_A,\n",
        "                                 'images/{}/{}/epoch{}_sample{}.png'.format(\n",
        "                                     self.date_time, 'A' + testString, epoch, i))\n",
        "            self.truncateAndSave(real_image_Ba, real_image_B, synthetic_image_A, reconstructed_image_B,\n",
        "                                 'images/{}/{}/epoch{}_sample{}.png'.format(\n",
        "                                     self.date_time, 'B' + testString, epoch, i))\n",
        "\n",
        "    def save_tmp_images(self, real_image_A, real_image_B, synthetic_image_A, synthetic_image_B):\n",
        "        try:\n",
        "            reconstructed_image_A = self.G_B2A.predict(synthetic_image_B)\n",
        "            reconstructed_image_B = self.G_A2B.predict(synthetic_image_A)\n",
        "\n",
        "            real_images = np.vstack((real_image_A[0], real_image_B[0]))\n",
        "            synthetic_images = np.vstack((synthetic_image_B[0], synthetic_image_A[0]))\n",
        "            reconstructed_images = np.vstack((reconstructed_image_A[0], reconstructed_image_B[0]))\n",
        "\n",
        "            self.truncateAndSave(None, real_images, synthetic_images, reconstructed_images,\n",
        "                                 'images/{}/{}.png'.format(\n",
        "                                     self.date_time, 'tmp'))\n",
        "        except: # Ignore if file is open\n",
        "            pass\n",
        "\n",
        "    def get_lr_linear_decay_rate(self):\n",
        "        # Calculate decay rates\n",
        "        if self.use_data_generator:\n",
        "            max_nr_images = len(self.data_generator)\n",
        "        else:\n",
        "            max_nr_images = max(len(self.A_train), len(self.B_train))\n",
        "\n",
        "        updates_per_epoch_D = 2 * max_nr_images + self.discriminator_iterations - 1\n",
        "        updates_per_epoch_G = max_nr_images + self.generator_iterations - 1\n",
        "        if self.use_identity_learning:\n",
        "            updates_per_epoch_G *= (1 + 1 / self.identity_mapping_modulus)\n",
        "        denominator_D = (self.epochs - self.decay_epoch) * updates_per_epoch_D\n",
        "        denominator_G = (self.epochs - self.decay_epoch) * updates_per_epoch_G\n",
        "        decay_D = self.learning_rate_D / denominator_D\n",
        "        decay_G = self.learning_rate_G / denominator_G\n",
        "\n",
        "        return decay_D, decay_G\n",
        "\n",
        "    def update_lr(self, model, decay):\n",
        "        new_lr = K.get_value(model.optimizer.lr) - decay\n",
        "        if new_lr < 0:\n",
        "            new_lr = 0\n",
        "        # print(K.get_value(model.optimizer.lr))\n",
        "        K.set_value(model.optimizer.lr, new_lr)\n",
        "\n",
        "    def print_ETA(self, start_time, epoch, epoch_iterations, loop_index):\n",
        "        passed_time = time.time() - start_time\n",
        "\n",
        "        iterations_so_far = ((epoch - 1) * epoch_iterations + loop_index) / self.batch_size\n",
        "        iterations_total = self.epochs * epoch_iterations / self.batch_size\n",
        "        iterations_left = iterations_total - iterations_so_far\n",
        "        eta = round(passed_time / (iterations_so_far + 1e-5) * iterations_left)\n",
        "\n",
        "        passed_time_string = str(datetime.timedelta(seconds=round(passed_time)))\n",
        "        eta_string = str(datetime.timedelta(seconds=eta))\n",
        "        print('Time passed', passed_time_string, ': ETA in', eta_string)\n",
        "\n",
        "\n",
        "#===============================================================================\n",
        "# Save and load\n",
        "\n",
        "    def saveModel(self, model, epoch):\n",
        "        # Create folder to save model architecture and weights\n",
        "        directory = os.path.join('saved_models', self.date_time)\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "\n",
        "        model_path_w = 'saved_models/{}/{}_weights_epoch_{}.hdf5'.format(self.date_time, model.name, epoch)\n",
        "        model.save_weights(model_path_w)\n",
        "        model_path_m = 'saved_models/{}/{}_model_epoch_{}.json'.format(self.date_time, model.name, epoch)\n",
        "        model.save_weights(model_path_m)\n",
        "        json_string = model.to_json()\n",
        "        with open(model_path_m, 'w') as outfile:\n",
        "            json.dump(json_string, outfile)\n",
        "        print('{} has been saved in saved_models/{}/'.format(model.name, self.date_time))\n",
        "\n",
        "    def writeLossDataToFile(self, history):\n",
        "        keys = sorted(history.keys())\n",
        "        with open('images/{}/loss_output.csv'.format(self.date_time), 'w') as csv_file:\n",
        "            writer = csv.writer(csv_file, delimiter=',')\n",
        "            writer.writerow(keys)\n",
        "            writer.writerows(zip(*[history[key] for key in keys]))\n",
        "\n",
        "    def writeMetaDataToJSON(self):\n",
        "\n",
        "        directory = os.path.join('images', self.date_time)\n",
        "        if not os.path.exists(directory):\n",
        "            os.makedirs(directory)\n",
        "        # Save meta_data\n",
        "        data = {}\n",
        "        data['meta_data'] = []\n",
        "        data['meta_data'].append({\n",
        "            'img shape: height,width,channels': self.img_shape,\n",
        "            'batch size': self.batch_size,\n",
        "            'save interval': self.save_interval,\n",
        "            'normalization function': str(self.normalization),\n",
        "            'lambda_1': self.lambda_1,\n",
        "            'lambda_2': self.lambda_2,\n",
        "            'lambda_d': self.lambda_D,\n",
        "            'learning_rate_D': self.learning_rate_D,\n",
        "            'learning rate G': self.learning_rate_G,\n",
        "            'epochs': self.epochs,\n",
        "            'use linear decay on learning rates': self.use_linear_decay,\n",
        "            'use multiscale discriminator': self.use_multiscale_discriminator,\n",
        "            'epoch where learning rate linear decay is initialized (if use_linear_decay)': self.decay_epoch,\n",
        "            'generator iterations': self.generator_iterations,\n",
        "            'discriminator iterations': self.discriminator_iterations,\n",
        "            'use patchGan in discriminator': self.use_patchgan,\n",
        "            'beta 1': self.beta_1,\n",
        "            'beta 2': self.beta_2,\n",
        "            'REAL_LABEL': self.REAL_LABEL,\n",
        "            'number of A train examples': len(self.A_train),\n",
        "            'number of B train examples': len(self.B_train),\n",
        "            'number of A test examples': len(self.A_test),\n",
        "            'number of B test examples': len(self.B_test),\n",
        "        })\n",
        "\n",
        "        with open('images/{}/meta_data.json'.format(self.date_time), 'w') as outfile:\n",
        "            json.dump(data, outfile, sort_keys=True)\n",
        "\n",
        "    def load_model_and_weights(self, model):\n",
        "        path_to_model = os.path.join('generate_images', 'models', '{}.json'.format(model.name))\n",
        "        path_to_weights = os.path.join('generate_images', 'models', '{}.hdf5'.format(model.name))\n",
        "        #model = model_from_json(path_to_model)\n",
        "        model.load_weights(path_to_weights)\n",
        "\n",
        "    def load_model_and_generate_synthetic_images(self):\n",
        "        response = input('Are you sure you want to generate synthetic images instead of training? (y/n): ')[0].lower()\n",
        "        if response == 'y':\n",
        "            self.load_model_and_weights(self.G_A2B)\n",
        "            self.load_model_and_weights(self.G_B2A)\n",
        "            synthetic_images_B = self.G_A2B.predict(self.A_test)\n",
        "            synthetic_images_A = self.G_B2A.predict(self.B_test)\n",
        "\n",
        "            def save_image(image, name, domain):\n",
        "                if self.channels == 1:\n",
        "                    image = image[:, :, 0]\n",
        "                toimage(image, cmin=-1, cmax=1).save(os.path.join(\n",
        "                    'generate_images', 'synthetic_images', domain, name))\n",
        "\n",
        "            # Test A images\n",
        "            for i in range(len(synthetic_images_A)):\n",
        "                # Get the name from the image it was conditioned on\n",
        "                name = self.testB_image_names[i].strip('.png') + '_synthetic.png'\n",
        "                synt_A = synthetic_images_A[i]\n",
        "                save_image(synt_A, name, 'A')\n",
        "\n",
        "            # Test B images\n",
        "            for i in range(len(synthetic_images_B)):\n",
        "                # Get the name from the image it was conditioned on\n",
        "                name = self.testA_image_names[i].strip('.png') + '_synthetic.png'\n",
        "                synt_B = synthetic_images_B[i]\n",
        "                save_image(synt_B, name, 'B')\n",
        "\n",
        "            print('{} synthetic images have been generated and placed in ./generate_images/synthetic_images'\n",
        "                  .format(len(self.A_test) + len(self.B_test)))\n",
        "\n",
        "\n",
        "# reflection padding taken from\n",
        "# https://github.com/fastai/courses/blob/master/deeplearning2/neural-style.ipynb\n",
        "class ReflectionPadding2D(Layer):\n",
        "    def __init__(self, padding=(1, 1), **kwargs):\n",
        "        self.padding = tuple(padding)\n",
        "        self.input_spec = [InputSpec(ndim=4)]\n",
        "        super(ReflectionPadding2D, self).__init__(**kwargs)\n",
        "\n",
        "    def compute_output_shape(self, s):\n",
        "        return (s[0], s[1] + 2 * self.padding[0], s[2] + 2 * self.padding[1], s[3])\n",
        "\n",
        "    def call(self, x, mask=None):\n",
        "        w_pad, h_pad = self.padding\n",
        "        return tf.pad(x, [[0, 0], [h_pad, h_pad], [w_pad, w_pad], [0, 0]], 'REFLECT')\n",
        "\n",
        "\n",
        "class ImagePool():\n",
        "    def __init__(self, pool_size):\n",
        "        self.pool_size = pool_size\n",
        "        if self.pool_size > 0:\n",
        "            self.num_imgs = 0\n",
        "            self.images = []\n",
        "\n",
        "    def query(self, images):\n",
        "        if self.pool_size == 0:\n",
        "            return images\n",
        "        return_images = []\n",
        "        for image in images:\n",
        "            if len(image.shape) == 3:\n",
        "                image = image[np.newaxis, :, :, :]\n",
        "\n",
        "            if self.num_imgs < self.pool_size:  # fill up the image pool\n",
        "                self.num_imgs = self.num_imgs + 1\n",
        "                if len(self.images) == 0:\n",
        "                    self.images = image\n",
        "                else:\n",
        "                    self.images = np.vstack((self.images, image))\n",
        "\n",
        "                if len(return_images) == 0:\n",
        "                    return_images = image\n",
        "                else:\n",
        "                    return_images = np.vstack((return_images, image))\n",
        "\n",
        "            else:  # 50% chance that we replace an old synthetic image\n",
        "                p = random.uniform(0, 1)\n",
        "                if p > 0.5:\n",
        "                    random_id = random.randint(0, self.pool_size - 1)\n",
        "                    tmp = self.images[random_id, :, :, :]\n",
        "                    tmp = tmp[np.newaxis, :, :, :]\n",
        "                    self.images[random_id, :, :, :] = image[0, :, :, :]\n",
        "                    if len(return_images) == 0:\n",
        "                        return_images = tmp\n",
        "                    else:\n",
        "                        return_images = np.vstack((return_images, tmp))\n",
        "                else:\n",
        "                    if len(return_images) == 0:\n",
        "                        return_images = image\n",
        "                    else:\n",
        "                        return_images = np.vstack((return_images, image))\n",
        "\n",
        "        return return_images\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    GAN = CycleGAN()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HHTec2Ifgcnr"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jgMKPP1hgcqN"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCWmGKUTgcsl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lNe1nd0gcv-"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5BUVIfbXgYp8"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQs0C7g0gYsq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yrjzINvqgYvw"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}